# Path to train dataset
train:
  # ==================
  # Train Dataset
  # ==================
  type: 'SwinIR'
  mode: 'train'
  scale: 2
  patch_size: 96 # 32*2 

  train_HR: 'dataset/trainsets/trainH/DIV2K'
  train_LR: 'dataset/trainsets/trainL/DIV2K/DIV2K_train_LR_bicubic'
  
  batch_size: 32 # 4x8
  shuffle: True
  num_workers: 32

  gpu_ids: [0,1,2,3]

  # ==================
  # Training parameters
  # ==================
  loss: 'l1'
  optimizer: 'adam'
  lr: 0.0002 # 2e-4
  weight_decay: 0.0
  resume_optimizer: null
  step_save: 5000
  step_test: 5000 
  step_print: 200
  # ==================
  # Training scheduler
  # ==================
  scheduler: 'MultiStepLR'
  milestones: [250000, 400000, 450000, 475000, 500000] # 0.0002 0.0001 0.00005 0.000025 0.0000125 0.00000625
  gamma: 0.5

  save_path: 'experiments/'

  pretrained_sam: '/home/mayanze/PycharmProjects/SwinTF/sam_vit_h_4b8939.pth'
  pretrained_sam_img_size: 48

  precomputed: True # 如果是 True，则默认保存在 train_LR 的文件夹下
  yadapt_use_cuda: True

test:
  mode: 'test'
  scale: 2
  patch_size: 96 # 32*2

  test_HR: 'dataset/testsets/Set5/GTmod12'
  test_LR: 'dataset/testsets/Set5/LRbicx2' # 这里要注意在数据读入的时候要有＋号，不然不知道是放大多少倍

  batch_size: 1
  shuffle: False
  num_workers: 1

  pretrained_sam: '/home/mayanze/PycharmProjects/SwinTF/sam_vit_h_4b8939.pth'
  pretrained_sam_img_size: 48

  precomputed: True # 如果是 True，则默认保存在 test_LR 的文件夹下
  yadapt_use_cuda: True
  
network:
  upsacle: 2
  in_channels: 3
  image_size: 48  # 照抄的，不知道是什么意思  1024 // 4 //  8 = 32
  window_size: 8
  image_range: 1.0 # 图像是 0-1 还是 0-255
  depths: [6,6,6,6,6,6] # depth 必须为 2 的倍数
  embed_dim: 180 # 修改的部分
  num_heads: [6,6,6,6,6,6] # num_heads 必须为 2 的倍数
  mlp_ratio: 2
  upsampler: 'pixelshuffle'
  resi_connection: '1conv'

  

  # 断点续训练
  resume_network: null
  freeze_network: False
# Path to train dataset
train:
  # ==================
  # Train Dataset
  # ==================
  type: 'SwinIR'
  mode: 'train'
  scale: 2
  patch_size: 96

  train_HR: 'dataset/trainsets/trainH/DIV2K'
  train_LR: 'dataset/trainsets/trainL/DIV2K/DIV2K_train_LR_bicubic'
  
  train_yadapt: ''
  pretrained_sam: '/home/mayanze/PycharmProjects/SwinTF/sam_vit_h_4b8939.pth'

  batch_size: 32 # 4x8
  shuffle: True
  num_workers: 16

  gpu_ids: [0,1,2,3]

  # ==================
  # Training parameters
  # ==================
  loss: 'l1'
  optimizer: 'adam'
  lr: 0.0002 # 2e-4
  weight_decay: 0.0
  resume_optimizer: null
  step_save: 5000
  step_test: 5000
  step_print: 200
  # ==================
  # Training scheduler
  # ==================
  scheduler: 'MultiStepLR'
  milestones: [250000, 400000, 450000, 475000, 500000] #最终要到 10000000 step
  gamma: 0.5

  save_path: 'experiments/'

test:
  mode: 'test'
  scale: 2
  patch_size: 96

  test_HR: 'dataset/testsets/Set5/GTmod12'
  test_LR: 'dataset/testsets/Set5/LRbicx4' # 这里要注意在数据读入的时候要有＋号，不然不知道是放大多少倍
  pretrained_sam: '/home/mayanze/PycharmProjects/SwinTF/sam_vit_h_4b8939.pth'

  batch_size: 1
  shuffle: False
  num_workers: 1

network:
  upsacle: 2
  in_channels: 3
  image_size: 48  # 照抄的，不知道是什么意思
  window_size: 8
  image_range: 1.0 # 图像是 0-1 还是 0-255
  depths: [6,6,6,6,6,6]
  embed_dim: 180
  num_heads: [6,6,6,6,6,6]
  mlp_ratio: 2
  upsampler: 'pixelshuffle'
  resi_connection: '1conv'

  # 断点续训练
  resume_network: null
